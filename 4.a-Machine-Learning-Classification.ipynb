{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.a - Machine Learning : classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import et préparation du dataset\n",
    "\n",
    "Les résultats du notebook précédent ont mis en évidence le rôle de l'ensemble des variables du _dataset_ dans le montant du pourboire :  \n",
    "- `fare_amount`\n",
    "- `surcharge`\n",
    "- `tolls_amount`\n",
    "- `passenger_count`\n",
    "- `trip_distance`\n",
    "- `trip_time_in_secs`\n",
    "- `nuit_jour`\n",
    "- `jour_semaine`\n",
    "- `vendor_id`\n",
    "- `payment_type`\n",
    "- `vitesse_moyenne`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous nous intéresserons ici à prédire **si pourboire il y a**, à partir de ces variables. La prédiciton de son montant le cas échéant fera l'objet d'un autre notebook. À cette fin, nous étudierons les performances de plusieurs modèles de classification, sans fine-tuning, afin de se faire une idée des algorithmes qui performent le mieux sur nos données.\n",
    "\n",
    "Dans l'ordre, voici les modèles explorés :\n",
    "1. <span style=\"position:center; top:10px; right:5px; width:100px; height:90px; margin:10px;\">[Régression_logistique](#Régression-logistique)</span>\n",
    "2. <span style=\"position:center; top:10px; right:5px; width:100px; height:90px; margin:10px;\">[Arbre_de_décision](#Arbre-de-décision)</span>\n",
    "3. <span style=\"position:center; top:10px; right:5px; width:100px; height:90px; margin:10px;\">[Analyse_linéaire_discriminante](#Analyse-linéaire-discriminante)</span>\n",
    "4. <span style=\"position:center; top:10px; right:5px; width:100px; height:90px; margin:10px;\">[Bayésien naïf](#Bayésien-naïf)</span>\n",
    "4. <span style=\"position:center; top:10px; right:5px; width:100px; height:90px; margin:10px;\">[k-Nearest_Neighbor](#k-Nearest-Neighbor)</span>\n",
    "5. <span style=\"position:center; top:10px; right:5px; width:100px; height:90px; margin:10px;\">[SVM](#SVM)</span>\n",
    "\n",
    "Nous laisserons volontairement tous les paramètres des algorithmes par défaut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "#os.chdir('/Users/pierredesmet/Documents/Documents Word/Etudes/UTT/ENSAE/Python pour le Data Scientist')\n",
    "os.chdir('C:\\\\Users\\\\Alexis\\\\Google Drive\\\\Documents\\\\ENSAE\\\\Semestre 1\\\\Projet python\\\\')\n",
    "import pandas\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor,DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix,f1_score,precision_score,recall_score,mean_squared_error,r2_score,cohen_kappa_score,classification_report\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import importation\n",
    "\n",
    "# Import des données\n",
    "trips = importation.chargement_donnees()\n",
    "trips = importation.clean(trips)\n",
    "\n",
    "# Ajout de 2 variables (cf précédent notebook)\n",
    "trips['vitesse_moyenne'] = trips['trip_distance']/trips['trip_time_in_secs']\n",
    "trips['received_tips'] = (trips.tip_amount > 0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On sait que :\n",
    "- L'application de paiement (<span style=\"color: #fb4141\">vendor_id</span>) n'intervient pas dans la formation du pourboire (montré dans le notebook 3), non plus que le <span style=\"color: #fb4141\">medallion</span> ou la <span style=\"color: #fb4141\">hack_license</span> ;\n",
    "- Les variables `nuit_jour_jour` et <span style=\"color: #fb4141\">nuit_jour_nuit</span> sont linéairement dépendantes, car quand l'une d'elle vaut 1, l'autre vaut nécessairement 0. Il en va de même pour les jours de la semaine (<span style=\"color: #fb4141\">jour_semaine_Monday</span>, ... , `jour_semaine_Sunday`). Idem, la `vitesse_moyenne` d'un taxi est formée à partir des deux variables <span style=\"color: #fb4141\">trip_distance</span> et <span style=\"color: #fb4141\">trip_time_in_secs</span> ;\n",
    "- le prix de la course (<span style=\"color: #fb4141\">total_amount</span>) inclu le tip éventuellement laissé au chauffeur.\n",
    "- <span style=\"color: #fb4141\">pickup_datetime</span> et <span style=\"color: #fb4141\">dropoff_datetime</span> contiennent de l'information inutile sur les dates, heures, minutes, et secondes ; on ne va garder que jour/nuit et le jour de la semaine.\n",
    "\n",
    "À partir de ces constats nous supprimons les variables susnommées en rouge. En outre, les courses payées autrement que par carte bleue n'ont pas permis l'enregistrement d'un éventuel pourboire : on ne gardera donc que les courses payées avec ce moyen :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Courses avec pourboire : 97.02%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>surcharge</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>vitesse_moyenne</th>\n",
       "      <th>received_tips</th>\n",
       "      <th>nuit_jour_nuit</th>\n",
       "      <th>jour_semaine_Friday</th>\n",
       "      <th>jour_semaine_Saturday</th>\n",
       "      <th>jour_semaine_Sunday</th>\n",
       "      <th>jour_semaine_Thursday</th>\n",
       "      <th>jour_semaine_Tuesday</th>\n",
       "      <th>jour_semaine_Wednesday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002375</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009792</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004481</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.006733</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>12.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fare_amount  surcharge  tolls_amount  passenger_count  vitesse_moyenne  \\\n",
       "1           5.0        0.0           0.0                1         0.002375   \n",
       "8          20.5        0.0           0.0                1         0.009792   \n",
       "12         10.0        0.0           0.0                1         0.004481   \n",
       "13          7.5        0.0           0.0                6         0.006733   \n",
       "14         12.5        0.0           0.0                1         0.005000   \n",
       "\n",
       "   received_tips  nuit_jour_nuit  jour_semaine_Friday  jour_semaine_Saturday  \\\n",
       "1           True             0.0                  0.0                    0.0   \n",
       "8          False             1.0                  0.0                    0.0   \n",
       "12          True             0.0                  0.0                    0.0   \n",
       "13          True             0.0                  0.0                    0.0   \n",
       "14          True             0.0                  0.0                    0.0   \n",
       "\n",
       "    jour_semaine_Sunday  jour_semaine_Thursday  jour_semaine_Tuesday  \\\n",
       "1                   1.0                    0.0                   0.0   \n",
       "8                   1.0                    0.0                   0.0   \n",
       "12                  1.0                    0.0                   0.0   \n",
       "13                  1.0                    0.0                   0.0   \n",
       "14                  1.0                    0.0                   0.0   \n",
       "\n",
       "    jour_semaine_Wednesday  \n",
       "1                      0.0  \n",
       "8                      0.0  \n",
       "12                     0.0  \n",
       "13                     0.0  \n",
       "14                     0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips = trips[(trips['payment_type'] == 'CRD')]\n",
    "trips = pandas.get_dummies(data=trips, columns=['nuit_jour', 'jour_semaine'])\n",
    "trips = trips.drop(['vendor_id', 'medallion', 'hack_license', 'nuit_jour_jour', 'jour_semaine_Monday',\n",
    "                    'trip_distance', 'trip_time_in_secs', 'total_amount','pickup_datetime', 'dropoff_datetime',\n",
    "                    'payment_type','tip_amount'], axis=1)\n",
    "print('Courses avec pourboire : %.2f%%'%(np.sum(trips.received_tips)/len(trips.received_tips)*100))\n",
    "trips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation croisée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Séparons tout d'abord notre jeu de données *trips* en un échantillon d'apprentissage - sur lequel entraîner les modèles, et un échantillon de test - sur lequel faire des prédictions. La validation-croisée (_testset validation_) est utilisable ici car nous ne sommes pas en présence de données ordonnées (séries temporelles). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(trips, test_size = 0.2)\n",
    "y_train = train['received_tips']\n",
    "y_test = test['received_tips']\n",
    "\n",
    "x_train = train.drop(['received_tips'],axis = 1)\n",
    "x_test = test.drop(['received_tips'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Régression logistique\n",
    "\n",
    "Nous cherchons à prédire à partir des caractéristiques d'une course x_train(i) si le chauffeur a reçu un pourboire (1) ou non (0). Il s'agit donc d'un problème de classification binaire pour lequel la régression logistique est tout indiquée. On crée donc un modèle de régression logistique et on l'entraînons sur l'échantillon d'entraînement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients :  [[-0.02595186 -0.02425783  0.02583993 -0.06564043  0.03503838 -0.22364905\n",
      "  -0.12323402 -0.20117243 -0.21990498  0.03851619  0.00483904  0.07128539]] \n",
      "Intercept : [ 4.11298161] \n",
      "\n",
      "Échantillon d'entraînement :\n",
      "\tNombre de prédictions erronées : 11007 / 369876\n",
      "\tPrédictions correctes : 0.97%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.00      0.00      0.00     11007\n",
      "       True       0.97      1.00      0.98    358869\n",
      "\n",
      "avg / total       0.94      0.97      0.96    369876\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion :\n",
      " [[     0  11007]\n",
      " [     0 358869]]\n",
      "\n",
      "Échantillon test :\n",
      "\tNombre de prédictions erronées : 2755 / 92469\n",
      "\tPrédictions correctes : 0.97%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.00      0.00      0.00      2755\n",
      "       True       0.97      1.00      0.98     89714\n",
      "\n",
      "avg / total       0.94      0.97      0.96     92469\n",
      "\n",
      "Matrice de confusion :\n",
      " [[    0  2755]\n",
      " [    0 89714]]\n"
     ]
    }
   ],
   "source": [
    "# Coefficients\n",
    "logistic = LogisticRegression()\n",
    "logistic = logistic.fit(x_train,y_train)\n",
    "print('Coefficients : ',logistic.coef_,'\\nIntercept :',logistic.intercept_,'\\n')\n",
    "\n",
    "def analysis(x,y):\n",
    "    # Prédictions\n",
    "    predictions = logistic.predict(x)\n",
    "    erreurs = np.sum(y != predictions)\n",
    "    print('\\tNombre de prédictions erronées :',erreurs,'/',len(y))\n",
    "    print('\\tPrédictions correctes : %.2f%%'%logistic.score(x,y))\n",
    "    # Qualité du modèle\n",
    "    print(classification_report(y, predictions))\n",
    "    print('Matrice de confusion :\\n',confusion_matrix(y, predictions))\n",
    "    \n",
    "# Échantillon d'entraînement\n",
    "print('Échantillon d\\'entraînement :')\n",
    "analysis(x_train,y_train)\n",
    "\n",
    "# Échantillon test\n",
    "print('\\nÉchantillon test :')\n",
    "analysis(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Que s'est-il passé ? \n",
    "Les performances du modèles semblent _a priori_ excellentes, comme en témoignent :\n",
    "- le taux de prédictions correctes avoisinant les 98% pour les jeux de test et d'apprentissage ;\n",
    "- la matrice de confusion, dont les coefficients non-diagonaux sont élevés ;\n",
    "- le `F1_score`, plus proche de 1 que de 0. \n",
    "> The F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0. `F1_score` $= 2 \\times \\frac{\\text{precision } \\times \\text{ recall}}{\\text{precision + recall}}$\n",
    "\n",
    "Cependant, deux éléments doivent nous alerter : \n",
    "- la proportion de pourboire laissés est de 97% : nous sommes en présence \"d'unbalanced class\". Le score du modèle n'est finalement pas très différent de celui que fournirait un algorithme naïf en prédisant systématiquement la classe modale ;\n",
    "- la matrice de confusion montre que c'est précisément ce qui s'est passé : le modèle n'a pas appris, et s'est contenté de prédire plus souvent des pourboires, puisque c'est comme ça que 97% des courses se concluent !\n",
    "\n",
    "Une solution que nous proposons de mettre en place est la constitution d'un jeu contenant autant (ou presque) de courses avec pourboires que de courses sans pourboire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "without_tips = trips.loc[trips.received_tips == False]\n",
    "with_tips = trips.loc[trips.received_tips == True].sample(len(without_tips))\n",
    "trips_balanced = pandas.concat([without_tips,with_tips])\n",
    "\n",
    "train, test = train_test_split(trips_balanced, test_size = 0.2)\n",
    "y_train = train['received_tips']\n",
    "y_test = test['received_tips']\n",
    "\n",
    "x_train = train.drop(['received_tips'],axis = 1)\n",
    "x_test = test.drop(['received_tips'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On relance alors la régression logistique sur le nouveau jeu de données équilibré obtenu :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients :  [[-0.0237815  -0.03429793  0.01333966 -0.07129146  0.1595065  -0.2903644\n",
      "  -0.12487918 -0.22423795 -0.24623045 -0.04948964 -0.03860138  0.0419841 ]] \n",
      "Intercept : [ 0.67142975] \n",
      "\n",
      "Échantillon d'entraînement :\n",
      "\tNombre de prédictions erronées : 9603 / 22019\n",
      "\tPrédictions correctes : 0.56%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.57      0.50      0.53     11008\n",
      "       True       0.56      0.63      0.59     11011\n",
      "\n",
      "avg / total       0.56      0.56      0.56     22019\n",
      "\n",
      "Matrice de confusion :\n",
      " [[5506 5502]\n",
      " [4101 6910]]\n",
      "\n",
      "Échantillon test :\n",
      "\tNombre de prédictions erronées : 2378 / 5505\n",
      "\tPrédictions correctes : 0.57%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.58      0.51      0.54      2754\n",
      "       True       0.56      0.63      0.59      2751\n",
      "\n",
      "avg / total       0.57      0.57      0.57      5505\n",
      "\n",
      "Matrice de confusion :\n",
      " [[1402 1352]\n",
      " [1026 1725]]\n"
     ]
    }
   ],
   "source": [
    "# Coefficients\n",
    "logistic = logistic.fit(x_train,y_train)\n",
    "\n",
    "#logistic = logistic.fit(x_train,y_train)\n",
    "print('Coefficients : ',logistic.coef_,'\\nIntercept :',logistic.intercept_,'\\n')\n",
    "    \n",
    "# Échantillon d'entraînement\n",
    "print('Échantillon d\\'entraînement :')\n",
    "analysis(x_train,y_train)\n",
    "\n",
    "# Échantillon test\n",
    "print('\\nÉchantillon test :')\n",
    "analysis(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette fois le modèle semble avoir appris (pas beaucoup). Le taux de prédictions correctes sur l'échantillon test avoisine les 57%, ce qui n'est tout de même pas très bon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À partir de là, il est possible de faire de la prédiction pour une nouvelle course.\n",
    "Prenons par exemple la course fictive suivante :\n",
    "\n",
    "| `fare_amount` | `surcharge` | `tolls_amount` | `passenger_count` | `vitesse_moyenne` | `trip_jour_nuit` | `jour_semaine_Saturday` |\n",
    "|:-----------:|:---------:|:------------:|:---------------:|:-------------:|:-----------------:|:--------------:|:-------------:|:--------------------:|:---------------:|\n",
    "|      3     |     0     |       0      |        4        |      0.00175      |       0        |        1       |  \n",
    "\n",
    "Le chauffeur d'une telle course peut-il s'attendre à un pourboire ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le chauffeur peut s'attendre à un pourboire : [False]\n"
     ]
    }
   ],
   "source": [
    "data = {'fare_amount':3, 'surcharge':0, 'tolls_amount':0, 'passenger_count':4,\n",
    "        'vitesse_moyenne': 0.00175,'nuit_jour_nuit':0,\n",
    "        'jour_semaine_Tuesday':0,'jour_semaine_Wednesday':0, 'jour_semaine_Thursday':0,\n",
    "        'jour_semaine_Friday':0,'jour_semaine_Saturday':1, 'jour_semaine_Sunday':0}\n",
    "my_single_course = pandas.DataFrame(data = data, index = [0])\n",
    "print('Le chauffeur peut s\\'attendre à un pourboire :',logistic.predict(my_single_course))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arbre de décision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la perspective de comparer le modèle précédent à un autre, nous essayons à présent de prédire si le chauffeur recevra un pourboire _via_ un arbre de décision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le chauffeur peut s'attendre à un pourboire : [False]\n",
      "\tNombre de prédictions erronées : 2666 / 5505\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.52      0.52      0.52      2754\n",
      "       True       0.52      0.51      0.51      2751\n",
      "\n",
      "avg / total       0.52      0.52      0.52      5505\n",
      "\n",
      "Matrice de confusion :\n",
      " [[1429 1325]\n",
      " [1341 1410]]\n"
     ]
    }
   ],
   "source": [
    "my_tree = DecisionTreeClassifier()\n",
    "my_tree = my_tree.fit(x_train,y_train)\n",
    "\n",
    "# Prédiction de la course précédente :\n",
    "print('Le chauffeur peut s\\'attendre à un pourboire :',my_tree.predict(my_single_course))\n",
    "\n",
    "def analysis_tree(x,y):\n",
    "    # Prédictions\n",
    "    predictions = my_tree.predict(x)\n",
    "    erreurs = np.sum(y != predictions)\n",
    "    print('\\tNombre de prédictions erronées :',erreurs,'/',len(y))\n",
    "    # Qualité du modèle\n",
    "    print(classification_report(y_test, predictions))\n",
    "    print('Matrice de confusion :\\n',confusion_matrix(y,predictions))\n",
    "\n",
    "# Prédictions sur l'ensemble test :\n",
    "analysis_tree(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats d'un arbre étant excessivement mauvais, on s'abstiendra d'étudier le modèle de random forest, celui-ci étant construit sur des arbres de décision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse linéaire discriminante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de prédictions erronées : 2377 / 5505\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.58      0.51      0.54      2754\n",
      "       True       0.56      0.63      0.59      2751\n",
      "\n",
      "avg / total       0.57      0.57      0.57      5505\n",
      "\n",
      "Matrice de confusion :\n",
      " [[1397 1357]\n",
      " [1020 1731]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "clf = LinearDiscriminantAnalysis(solver = 'lsqr')\n",
    "clf.fit(x_train, y_train)\n",
    "predictions = clf.predict(x_test)\n",
    "erreurs = np.sum(y_test != predictions)\n",
    "print('Nombre de prédictions erronées :',erreurs,'/',len(y_test))\n",
    "print(classification_report(y_test, predictions))\n",
    "print('Matrice de confusion :\\n',confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayésien naïf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.53      0.75      0.62      2754\n",
      "       True       0.57      0.34      0.43      2751\n",
      "\n",
      "avg / total       0.55      0.54      0.52      5505\n",
      "\n",
      "[[2056  698]\n",
      " [1817  934]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "naif = GaussianNB()\n",
    "naif.fit(x_train, y_train)\n",
    "predictions = naif.predict(x_test)\n",
    "print(classification_report(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.52      0.52      0.52      2754\n",
      "       True       0.52      0.52      0.52      2751\n",
      "\n",
      "avg / total       0.52      0.52      0.52      5505\n",
      "\n",
      "[[1420 1334]\n",
      " [1309 1442]]\n"
     ]
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier()\n",
    "neigh.fit(x_train, y_train)\n",
    "predictions = neigh.predict(x_test)\n",
    "print(neigh)\n",
    "print(classification_report(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.57      0.48      0.52      2754\n",
      "       True       0.55      0.63      0.59      2751\n",
      "\n",
      "avg / total       0.56      0.56      0.55      5505\n",
      "\n",
      "[[1320 1434]\n",
      " [1011 1740]]\n"
     ]
    }
   ],
   "source": [
    "model = SVC()\n",
    "model.fit(x_train,y_train)\n",
    "predictions = model.predict(x_test)\n",
    "print(model)\n",
    "print(classification_report(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Decision_tree</th>\n",
       "      <th>Discriminant_analysis</th>\n",
       "      <th>Logistic_model</th>\n",
       "      <th>Naive_Bayes_classifier</th>\n",
       "      <th>SVM</th>\n",
       "      <th>k-Nearest_Neighbor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score_test</th>\n",
       "      <td>0.515713</td>\n",
       "      <td>0.568211</td>\n",
       "      <td>0.568029</td>\n",
       "      <td>0.543143</td>\n",
       "      <td>0.555858</td>\n",
       "      <td>0.519891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_train</th>\n",
       "      <td>0.995004</td>\n",
       "      <td>0.564013</td>\n",
       "      <td>0.563877</td>\n",
       "      <td>0.543621</td>\n",
       "      <td>0.581180</td>\n",
       "      <td>0.698124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Decision_tree  Discriminant_analysis  Logistic_model  \\\n",
       "score_test        0.515713               0.568211        0.568029   \n",
       "score_train       0.995004               0.564013        0.563877   \n",
       "\n",
       "             Naive_Bayes_classifier       SVM  k-Nearest_Neighbor  \n",
       "score_test                 0.543143  0.555858            0.519891  \n",
       "score_train                0.543621  0.581180            0.698124  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthese_algo = {\n",
    "    'Logistic_model': {'score_train': logistic.score(x_train,y_train), 'score_test': logistic.score(x_test,y_test)},\n",
    "    'Decision_tree': {'score_train': my_tree.score(x_train, y_train), 'score_test': my_tree.score(x_test, y_test)},\n",
    "    'Discriminant_analysis': {'score_train': clf.score(x_train, y_train), 'score_test': clf.score(x_test, y_test)},\n",
    "    'Naive_Bayes_classifier': {'score_train': naif.score(x_train, y_train), 'score_test': naif.score(x_test, y_test)},\n",
    "    'k-Nearest_Neighbor': {'score_train': neigh.score(x_train, y_train), 'score_test': neigh.score(x_test, y_test)},\n",
    "    'SVM': {'score_train': model.score(x_train, y_train), 'score_test': model.score(x_test, y_test)}\n",
    "}\n",
    "pandas.DataFrame(synthese_algo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut conclure que prédire qu'un trajet ne conduira pas à un pourboire est un problème difficile. On peut supposer que c'est parce qu'il n'existe pas de structure qui explique cette action, et qu'à partir des données que l'on possède, ces trajets apparaissent comme totalement aléatoire.\n",
    "\n",
    "En revanche, nous allons voir dans le prochain notebook que prédire la valeur du pourboire est un problème plus simple.\n",
    "\n",
    "On note qu'on pourrait à priori penser qu'il est plus simple de prédire pourboire/pas de pourboire que de donner la valeur de celui-ci. On verra que ce n'est pas le cas ici."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
